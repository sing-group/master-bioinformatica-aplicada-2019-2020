{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook guides you trough a simple example of colorectal histology images classification using Deep Learning.\n",
    "\n",
    "We will be using this [Collection of textures in colorectal cancer histology](https://zenodo.org/record/53169#.XjBUGOGCGXn), which contains 5000 histological images of 150 * 150 px each. Each image belongs to exactly one of eight tissue categories (specified by the folder name).\n",
    "\n",
    "Let's get started by importing the neccessary modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "import pathlib\n",
    "import IPython.display as display\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, set the paths of the images and load the class names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = pathlib.Path(\"Kather_texture_2016_image_tiles_5000/\")\n",
    "image_count = len(list(data_dir.glob('*/*.tif')))\n",
    "print(\"There are \" + str(image_count) + \" images\")\n",
    "\n",
    "CLASS_NAMES = np.array([item.name for item in data_dir.glob('*') if item.name != \"LICENSE.txt\"])\n",
    "print(\"The class names are: \" + str(CLASS_NAMES))\n",
    "\n",
    "images_list_example = list(data_dir.glob('07_ADIPOSE/*'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display a single image from the list to see how it looks like. Feel free to change the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display.display(Image.open(str(images_list_example[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure the image loaders. For this, the `ImageDataGenerator` class of Keras is used to define one loader for the training dataset and another one for the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "\n",
    "# The 1./255 is to convert from uint8 to float32 in range [0,1].\n",
    "image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255, validation_split = 0.2)\n",
    "\n",
    "train_data_gen = image_generator.flow_from_directory(\n",
    "    seed=2020,\n",
    "    directory=str(data_dir),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    classes = list(CLASS_NAMES),\n",
    "    subset='training')\n",
    "\n",
    "val_data_gen = image_generator.flow_from_directory(\n",
    "    seed=2020,\n",
    "    directory=str(data_dir),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    classes = list(CLASS_NAMES),\n",
    "    subset='validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use Transfer Learning. For this, we will take advantage of the TensorFlow Hub, which distributes models without the top classification layer. These can be used to easily do transfer learning.\n",
    "\n",
    "All we have to do is to download a model from the TensorFlow Hub and retrain the top layer of the model to recognize the classes in our dataset.\n",
    "\n",
    "Any [Tensorflow 2 compatible image feature vector URL](https://tfhub.dev/s?module-type=image-feature-vector&q=tf2) from tfhub.dev will work here. Let's use the `MobileNetV2` model trained on the ImageNet dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor_url = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/2\" #@param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, we create the feature extractor layer using this URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor_layer = hub.KerasLayer(feature_extractor_url, input_shape=(224,224,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we uncomment the following line, we will freeze the variables in the feature extractor layer, so that the training only modifies the new classifier layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_extractor_layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it is time to wrap the hub layer in a tf.keras.Sequential model, and add a new classification layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  feature_extractor_layer,\n",
    "  layers.Dense(train_data_gen.num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model. Let's use compile to configure the training process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(),\n",
    "  loss='categorical_crossentropy',\n",
    "  metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use the `.fit` method to train the model.\n",
    "\n",
    "To keep this example short train a few epochs (e.g. 3). To visualize the training progress, use a custom callback to log the loss and accuracy of each batch individually, instead of the epoch average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CollectBatchStats(tf.keras.callbacks.Callback):\n",
    "  def __init__(self):\n",
    "    self.batch_losses = []\n",
    "    self.batch_acc = []\n",
    "\n",
    "  def on_train_batch_end(self, batch, logs=None):\n",
    "    self.batch_losses.append(logs['loss'])\n",
    "    self.batch_acc.append(logs['acc'])\n",
    "    self.model.reset_metrics()\n",
    "\n",
    "steps_per_epoch = np.ceil(train_data_gen.samples/train_data_gen.batch_size)\n",
    "\n",
    "batch_stats_callback = CollectBatchStats()\n",
    "\n",
    "history = model.fit(train_data_gen, epochs=3,\n",
    "                              steps_per_epoch=steps_per_epoch,\n",
    "                              validation_data = val_data_gen, \n",
    "                              callbacks = [batch_stats_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot loss and accuracy to track the progress of the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylim([0,2])\n",
    "plt.plot(batch_stats_callback.batch_losses)\n",
    "\n",
    "plt.figure()\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylim([0,1])\n",
    "plt.plot(batch_stats_callback.batch_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, use the trained model to check the predictions on the validation set. To do this, the `val_data_gen` is created again so that we can iterate over all the images.\n",
    "\n",
    "The code bellow iterates trough each group of 32 (`BATCH_SIZE`) validation images, printing them together with the predicted labels in green if the predictions are right and in red if the predictions are wrong.\n",
    "\n",
    "To have the example finished early, only two groups are printed. Uncomment the line that says `if batch_count == len(val_data_gen):` in order to print them all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data_gen = image_generator.flow_from_directory(\n",
    "    seed=2020,\n",
    "    directory=str(data_dir),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    classes = list(CLASS_NAMES),\n",
    "    subset='validation')\n",
    "\n",
    "\n",
    "class_names = sorted(val_data_gen.class_indices.items(), key=lambda pair:pair[1])\n",
    "class_names = np.array([key.title() for key, value in class_names])\n",
    "class_names\n",
    "\n",
    "batch_count = 0\n",
    "for image_batch, label_batch in val_data_gen:\n",
    "    batch_count = batch_count + 1;\n",
    "    \n",
    "    predicted_batch = model.predict(image_batch)\n",
    "    predicted_id = np.argmax(predicted_batch, axis=-1)\n",
    "    predicted_label_batch = class_names[predicted_id]\n",
    "\n",
    "    label_id = np.argmax(label_batch, axis=-1)\n",
    "\n",
    "    plt.figure(figsize=(10,19))\n",
    "    plt.subplots_adjust(hspace=0.8)\n",
    "    for n in range(image_batch.shape[0]):\n",
    "        plt.subplot(8,4,n+1)\n",
    "        plt.imshow(image_batch[n])\n",
    "        color = \"green\" if predicted_id[n] == label_id[n] else \"red\"\n",
    "        title = predicted_label_batch[n].title() if predicted_id[n] == label_id[n] else predicted_label_batch[n].title() + \"(\" + class_names[label_id[n]] + \")\"\n",
    "        plt.title(predicted_label_batch[n].title(), color=color)\n",
    "        plt.axis('off')\n",
    "        _ = plt.suptitle(\"Model predictions (green: correct, red: incorrect) for batch \" + str(batch_count))\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "    # if batch_count == len(val_data_gen):\n",
    "    if batch_count == 2:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
